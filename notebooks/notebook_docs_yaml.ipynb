{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/squadOito/soulcodead2/blob/joseaureliok%2Fnotebook/notebooks/notebook_docs_yaml.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Projeto Final**\n",
        "Escola: SoulCode Academy\n",
        "\n",
        "Curso: Bootcamp Analista de Dados - Martech - AD2\n",
        "\n",
        "**Alunos: Nomes, Nomes**\n",
        "\n",
        "Professores: Douglas Ribeiro e Franciane Rodrigues"
      ],
      "metadata": {
        "id": "8AvV2uVhNLpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparação de Ambiente"
      ],
      "metadata": {
        "id": "L7abbfpEBjvV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cGTV4K2w0xhZ"
      },
      "outputs": [],
      "source": [
        "# Instalaçao Bibliotecas\n",
        "!pip install gcsfs -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando Bibliotecas\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "from google.cloud import storage\n",
        "from google.colab import drive\n",
        "from google.colab import auth\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "metadata": {
        "id": "9PyA1knO9Wau"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ignorando alguns alertas desnecessários\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "um2OUpf69mnW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configuração PySpark"
      ],
      "metadata": {
        "id": "iw_HBWma1nHd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -N -q http://archive.apache.org/dist/spark/spark-3.1.1/spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark"
      ],
      "metadata": {
        "id": "Zzgp2wP_J1zP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop3.2\""
      ],
      "metadata": {
        "id": "WqPM27dsJ2jp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "\n",
        "from pyspark.sql.functions import regexp_replace\n",
        "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True) # Para deixar a visualição das tabelas mais amigável\n",
        "\n",
        "import pyspark.sql.functions as F\n",
        "from pyspark.sql.types import *\n",
        "\n",
        "spark"
      ],
      "metadata": {
        "id": "1sAWAoufKBBb",
        "outputId": "4a9bd5a8-9e52-40d0-a32b-6de0b49c8176",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x78c3e467c8e0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://74ab4f618edf:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.1.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compartilhamento Chave GDrive"
      ],
      "metadata": {
        "id": "J5R3Nt3Q1er7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cria compartilhamento com Google Drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Arquivo a ser acessado na pasta compartilhada\n",
        "\n",
        "target = 'projeto-final-ad2-e8-ae566c3a2c2b.json'\n",
        "\n",
        "# Caminho completo da pasta compartilhada\n",
        "folder = '/content/drive/MyDrive/Classroom/AD2 - Analista de Dados/ProjetoFinal'\n",
        "\n",
        "# Acesso ao arquivo no colab\n",
        "serviceAccount = os.path.join(folder, target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSoSXbShcQVp",
        "outputId": "efe75692-1483-4dd1-9afd-7447e1236bd1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configuração da bucket"
      ],
      "metadata": {
        "id": "0dZJqZvm1DES"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Conexão com a conta do Google Cloud\n",
        "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = serviceAccount"
      ],
      "metadata": {
        "id": "CyymFDdQ2akm"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Conexão com a bucket do Google Cloud\n",
        "client = storage.Client()\n",
        "bucket = client.get_bucket('projeto-final-ad2-e8')"
      ],
      "metadata": {
        "id": "TV-rH7EWbVpm"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conjuntos de dados"
      ],
      "metadata": {
        "id": "Aa2mhAJnEEYp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Caminho do arquivo\n",
        "path = 'gs://projeto-final-ad2-e8/dados/brutos/excel/iea_ponto_recarga_bruto.xlsx'"
      ],
      "metadata": {
        "id": "_f15se_jLs3O"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Funções"
      ],
      "metadata": {
        "id": "xM0iv87CENuK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# função de leitura no Spark\n",
        "def spark_excel(path):\n",
        "  try:\n",
        "\n",
        "    try:\n",
        "      # leitura csv com pandas\n",
        "      read = pd.read_excel(path)\n",
        "      # conversão em df pandas em df pyspark\n",
        "      df = spark.createDataFrame(read)\n",
        "      # êxito da função retornando o dataframe\n",
        "      return df\n",
        "\n",
        "    except:\n",
        "      # leitura csv com pandas\n",
        "      read = pd.read_excel(path)\n",
        "\n",
        "      # tratamento de tipo de dado do df pandas para conversão em df pyspark\n",
        "      for n in read.columns:\n",
        "        if read[f'{n}'].dtype == object:\n",
        "          read[f'{n}'] = read[f'{n}'].astype(str)\n",
        "        elif read[f'{n}'].dtype == bool:\n",
        "          read[f'{n}'] = read[f'{n}'].astype(bool)\n",
        "        else:\n",
        "          read[f'{n}'] = read[f'{n}'].astype(np.double)\n",
        "\n",
        "      # conversão df pandas em df pyspark\n",
        "      df = spark.createDataFrame(read)\n",
        "      # êxito da função retornando o dataframe\n",
        "      return df\n",
        "\n",
        "  except:\n",
        "    # indicação de erro na leitura do dataframe\n",
        "    print(f'Falha na leitura do DataFrame: {path}!')"
      ],
      "metadata": {
        "id": "w9B0qr7_HMOE"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# função de definição do Schema\n",
        "def docSchema(nome_dataset, dataframe, formato):\n",
        "  '''Após a criação do schema e preenchimento das informações em um editor\n",
        "  de texto, passar o conteúdo para validar no site: https://www.yamllint.com/'''\n",
        "# modelo de impressão dos dados\n",
        "  print(f\"\"\"\n",
        "nome: {nome_dataset}\n",
        "descricao:\n",
        "origem:\n",
        "tratamento: squadOito\n",
        "armazenamento: GCS\n",
        "acesso: privado\n",
        "formato: {formato}\n",
        "schema:\"\"\")\n",
        "# laço de repetição para todas as colunas do dataframe\n",
        "  for columns in dataframe.dtypes:\n",
        "    print(f\"\"\" - coluna: {columns[0]}\n",
        "   descricao:\n",
        "   tipo: {columns[1]}\"\"\")"
      ],
      "metadata": {
        "id": "o3bq9DJiBPX4"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Documentação"
      ],
      "metadata": {
        "id": "wgXTwxQXBMjK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Leitura do dataframe"
      ],
      "metadata": {
        "id": "1RUCtvRBEXmM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark_excel(path)"
      ],
      "metadata": {
        "id": "NZqEm8rfEXEm"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chamando função"
      ],
      "metadata": {
        "id": "wGdk4ByKEttU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "docSchema('iea_ponto_recarga_bruto', df, 'xlsx')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zINMo5KZEsCQ",
        "outputId": "f82537a5-5ded-4220-8c3e-d3d4e0e38c42"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "nome: iea_ponto_recarga_bruto\n",
            "descricao:\n",
            "origem:\n",
            "tratamento: squadOito\n",
            "armazenamento: GCS\n",
            "acesso: privado\n",
            "formato: xlsx\n",
            "schema:\n",
            " - coluna: region\n",
            "   descricao:\n",
            "   tipo: string\n",
            " - coluna: category\n",
            "   descricao:\n",
            "   tipo: string\n",
            " - coluna: parameter\n",
            "   descricao:\n",
            "   tipo: string\n",
            " - coluna: mode\n",
            "   descricao:\n",
            "   tipo: string\n",
            " - coluna: powertrain\n",
            "   descricao:\n",
            "   tipo: string\n",
            " - coluna: year\n",
            "   descricao:\n",
            "   tipo: bigint\n",
            " - coluna: unit\n",
            "   descricao:\n",
            "   tipo: string\n",
            " - coluna: value\n",
            "   descricao:\n",
            "   tipo: bigint\n"
          ]
        }
      ]
    }
  ]
}